<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[jenwang的随想]]></title>
  <link href="http://jenwang.me/atom.xml" rel="self"/>
  <link href="http://jenwang.me/"/>
  <updated>2017-01-30T19:52:49+08:00</updated>
  <id>http://jenwang.me/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://jenwang.me/">jenwang</generator>

  
  <entry>
    <title type="html"><![CDATA[茶书]]></title>
    <link href="http://jenwang.me/14856967077187.html"/>
    <updated>2017-01-29T21:31:47+08:00</updated>
    <id>http://jenwang.me/14856967077187.html</id>
    <content type="html"><![CDATA[
<p>作者: [日] 冈仓天心 </p>

<p><img src="media/14856967077187/14856968085208.jpg" alt=""/></p>

<blockquote>
<p>感想与摘录</p>
</blockquote>

<p>原以为是介绍喝茶知识的书，然而并不是。一直对日本诸多侘寂之美的设计颇为赞赏，简朴亲切而又实用摒弃任何多余的干扰，然而对于这种审美的根基一无所知，看完后又刷新了对日本的一些认知，对简约朴素的审美和文化之渊源有了全新的了解，甚是惊喜。<br/>
译者的后记是本书不可忽视的篇章，更通透地解释了中日文化渊源和差异，视角非常有启发。中国艺术的背后主要是权力、审美的统治，而日本则是普通民众的力量，民艺运动通过改善民众的生活品质进而促进社会进步。日本茶道的建立是对这种审美统治的挑战，属于自己空间关系的审美而非复制中国的审美，我们总是提传统文化的保护却很少钻研传统文化的发展，传统不应该成为包袱，应该随时蜕去积攒千年的壳，关照事物纯粹的本质，没有创造无所谓传统，传统是创造的积淀。极为认同译者所言<code>中国没有茶道，中国有饮茶的方法</code>，近年来大陆的饮茶之风日盛，只是附庸风雅、软弱无力，是虚假和令人生厌的，没有文化的优雅是妖，再多的人声鼎沸也只能是繁华躁动且妖气弥漫。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我和工具]]></title>
    <link href="http://jenwang.me/14851540366764.html"/>
    <updated>2017-01-23T14:47:16+08:00</updated>
    <id>http://jenwang.me/14851540366764.html</id>
    <content type="html"><![CDATA[
<p>好的工具对于提升效率、提高生活品质起到重要作用。梳理和分享下我正在使用的，本列表长期更新。</p>

<span id="more"></span><!-- more -->

<ul>
<li>保护眼睛

<ul>
<li>flux<br/>
过滤蓝光，晚上光线暗的时候不会那么刺眼，我在mac和安卓手机上使用，ios自带类似功能。<br/>
<a href="https://justgetflux.com/%E2%80%8B">https://justgetflux.com/​</a></li>
</ul></li>
<li>白噪音<br/>

<ul>
<li>我在mac上使用「Noizio」让自己更专注和沉浸于手头的事</li>
<li>手机上可以用微信小程序「小睡眠」</li>
</ul></li>
<li><p>todolist<br/><br/>
「奇妙清单」管理任务和提醒，全平台同步，还可通过webcal订阅到日历视图中（mac 日历支持 webcal url 订阅，安卓直接支持的很少，可安装 ICSdroid 解决）。</p></li>
<li><p>知识管理和文档编写<br/><br/>
基本只用 markdown 格式编写，除非特殊需要几乎不碰 word。  </p>

<ul>
<li>Simplenote<br/>
小而美，用来随手打开记录临时想法，后整理到其他地方。一般是在手机中记录，后在电脑上整理。</li>
<li><em>mweb</em><br/>
特别推荐，到目前为止同类工具中最称心的，markdown 是必须的，支持生成静态网站。适合个人的知识沉淀和写文字，存放整理后的资料。支持一篇文档属于多个分类，利用这一特性可以选取一些文档到博客分类下，这样公开博客和私有文档就能在同一知识沉淀工具上完成。数据通过 dropbox 同步。外部模式用来打开其他 markdown 文档，用了 mweb 后很少使用 macdown、mou 等 markdown 编辑器了。</li>
<li>印象笔记<br/>
主要用于收集，未经整理的资料，杂货桶。用来写作总不舒服，不展开说为什么，个人品味。 </li>
<li><del>为知笔记</del><br/>
前几年用，还放着历史遗留文档，只在查看相关资料时打开。后因 mac 端体验不太好，以及丢了几篇文档后逐步弃用。 </li>
</ul></li>
<li><p>幻灯片<br/><br/>
讨厌 ppt，也用不惯keynote。</p>

<ul>
<li>Marp<br/>
markdown 编写幻灯片，文档中通过<code>---</code>分割成一页幻灯片。目前所知同类工具中最简单方便的。曾给 mweb 的作者提过能否直接加上 Marp 的功能，这样文档和演示就能统一起来了，被否决（认为从技术角度会导致 mweb 太庞杂）。</li>
</ul></li>
<li><p>信息获取与新闻</p>

<ul>
<li>即刻，只订阅自己想关注的信息源。</li>
<li>小密圈</li>
</ul></li>
<li><p>图片处理</p>

<ul>
<li>Google Nik Collection，mac上用于照片后期处理，非常强大。</li>
<li>snapseed，手机上用。</li>
</ul></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何评价一个清闲的管理者]]></title>
    <link href="http://jenwang.me/14850506793674.html"/>
    <updated>2017-01-22T10:04:39+08:00</updated>
    <id>http://jenwang.me/14850506793674.html</id>
    <content type="html"><![CDATA[
<p>比如一个部门负责人看上去很「清闲」好不好？这个问题我认为不能从是否「清闲」来判断一个管理者，所谓善战者无赫赫之功也是极有可能的，重点在于他的团队氛围、工作效率如何。</p>

<p>假如管理者带来的影响是负面的，那么忙碌起来并没有意义，甚至还不如什么也不做，遗憾的是很大比例的管理者并不这么做，甚至知道也不能这么做，忙碌本身已经成为政治正确，不管事情真正的意义和价值。</p>

<span id="more"></span><!-- more -->

<p>一个负责人多数时间并没做具体事情，似乎比较「清闲」，而他的团队又是运作良好的（没出啥大问题，基本满足需求），那么就没必要去改变他，往往是他通过自身探索找到了某种节奏和平衡，组建了合适的梯队，负责人不在时团队也能运作良好是件值得高兴的事，这才是管理有方。</p>

<p>一旦外力去打破这种平衡那就会出问题，比如来了一个接替者，制定了一系列严格措施、流程、加班等等，似乎大家都有序忙碌起来了，其实隐含着危机，员工抱怨增多，工作严重挤占个人时间，付出汇报不成比例等等，底下员工的这种问题就是团队涣散的开始，往往还不容易被高层发现，为啥始终不见氛围和效率，这就是原因。另一种是貌似都已竭尽全力，工时很长，产出结果问题也很多，但是领导很满意，就要这种态度嘛，相关的管理者受到赏识，这就是劣币驱逐良币，劣币驱逐良币的事不能做大家都懂，但实际中要识别这种情况确不太容易，做了也不自知。</p>

<p>打破一个良好而清闲的管理者的动机，大概可归结为两种情况，1. 这么无所事事肯定没干好工作，2. 应该花更多的时间把工作做得更好。<br/><br/>
稍加推敲都是不成立的，第一种，无所事事只是你看起来的表面现象，实际可能是他通过一系列的努力跟团队之间达成的一种默契，从表面现象推断出工作结果就非常主观和不严谨，而应该从具体事实判断。<br/>
第二种，花更多个人时间不一定就能把工作做得更好，上面已经讲过瞎作为还不如不作为，一个人成绩达到90分想往100分努力，付出和回报是极不成比例的，既有可能永远也达不到目标，打破自身平衡去做远超能力之外的事情，往往结果不会好。</p>

<p>任何管理都不要违背人性，逼不得已可短期为之，但是一定不能也不会长久。管理要借助满足人性驱动效率，如果做不到就要反思哪里出了问题。</p>

<p>最后，在国内当前环境下，这些观点会被很多人认为是价值观有问题，以及政治不正确的。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一个使用本地缓存引起的线程阻塞问题]]></title>
    <link href="http://jenwang.me/14853486232734.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486232734.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">现象</h2>

<p>有同事的java系统运行一段时间后发生请求阻塞的情况(返回504)，从仅有的内存dump文件看，大部分线程都阻塞在了一个本地缓存（jodd cache）的读锁上了（ReentrantReadWriteLock$ReadLock.lock）。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">排查过程</h2>

<h3 id="toc_2">阶段一</h3>

<p>本能的反应应该是写锁被占用了才会出现这个情况。于是开始以&quot;WriteLock.lock&quot;为关键字搜索写锁，怎么也搜不到。其实搜不到是正常的，因为写锁已经被占有了,当然不可能停在WriteLock.lock上了。</p>

<p>开始翻jodd LRUCache代码，发现是用LinkedHashMap实现的，在dump文件上搜索LinkedHashMap写操作的代码，果然发现有一个线程是正在执行LRUCache的put方法，代码停留在LRUCache的pruneCache方法中(就是在put的时候cache满了回收一些位置)：</p>

<pre><code>protected int pruneCache() {
    if (isPruneExpiredActive() == false) {
        return 0;
    }
    int count = 0;
    //cacheMap就是一个LinkedHashMap的实例
    Iterator&lt;CacheObject&lt;K,V&gt;&gt; values = cacheMap.values().iterator();
    while (values.hasNext()) {
        CacheObject&lt;K,V&gt; co = values.next();
        if (co.isExpired() == true) {
            values.remove();
            count++;
        }
    }
    return count;
}
    
</code></pre>

<p>到这里就证明了最初的猜想是对的，写锁被占了才导致那么多读线程被堵住。  </p>

<blockquote>
<p>可以看出 jodd 使用 LinkedHashMap + ReentrantReadWriteLock 实现LRUCache是有性能问题的，一个写操作会锁住整个缓存，阻塞所有读操作。<u>这是第一个问题</u>。</p>
</blockquote>

<h3 id="toc_3">阶段二</h3>

<p>显然不能到此就结束了，要有更高的追求，继续分析LRUCache的具体实现，主要逻辑就是put时加上写锁，get时加上读锁，内部是一个开启了accessOrder的LinkedHashMap作为数据存储。</p>

<p>初看也貌似很正常没啥问题啊。其实开启了accessOrder的LinkedHashMap 多线程get是会有并发问题的，因为会把get到的元素移到双向链表最前面，看LinkedHashMap的get方法： </p>

<pre><code>public V get(Object key) {
    Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key);
    if (e == null)
        return null;
    e.recordAccess(this);
    return e.value;
} 

void recordAccess(HashMap&lt;K,V&gt; m) {
    LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m;
    if (lm.accessOrder) {
        lm.modCount++;
        remove();
        addBefore(lm.header);
    }
}
</code></pre>

<blockquote>
<p>可以看到这里改变链表结构是没有任何并发控制的，因此LinkedHashMap并发get是不OK的，jodd给get加了读锁是存在并发问题的（还不明白的请自行学习ReentrantReadWriteLock机制）。<u>这是第二个问题</u>。</p>
</blockquote>

<p>可以想象下高并发时链表被破坏成各种奇形怪状的情况（比较费脑力，我就不描述了），完全有可能让上面pruneCache（）方法中的values.hasNext()永远为true。这次刚好是停在LRUCache#pruneCache中，下次就有可能停在LinkedHashMap#transfer上，一旦写锁里面的代码块hang住，所有读线程全部堵住，而且这种问题出现几率不等，很难模拟重现。</p>

<h2 id="toc_4">JUC Bug</h2>

<p>另外顺便提一下某些早期JDK版本中存在的BUG  </p>

<p>ReentrantReadWriteLock可能在没有任何线程持有锁的情况下被hang住：<br/>
<a href="http://bugs.sun.com/view_bug.do?bug_id=6822370">http://bugs.sun.com/view_bug.do?bug_id=6822370</a><br/>
<a href="http://bugs.sun.com/view_bug.do?bug_id=6903249">http://bugs.sun.com/view_bug.do?bug_id=6903249</a></p>

<h2 id="toc_5">小结</h2>

<ul>
<li>不要使用Jodd的cache</li>
<li>推荐使用gauva的cache<br/>
基于<a href="https://code.google.com/p/concurrentlinkedhashmap/">concurrentlinkedhashmap</a>实现，现已整合到guava里了</li>
<li>不可轻信开源组件，使用前一定要先研究透彻</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何一次性下载某个类库依赖的所有jar包"]]></title>
    <link href="http://jenwang.me/14853486232530.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486232530.html</id>
    <content type="html"><![CDATA[
<p>** 经常碰到这种事情: **</p>

<p>在一些非maven工程中(由于某种原因这种工程还是手工添加依赖的),需要用到某个新的类库(假设这个类库发布在maven库中),而这个类库又间接依赖很多其他类库,如果依赖路径非常复杂的话,一个个检查手动下载是很麻烦的事. </p>

<p>** 下面给出一个便捷的办法: **</p>

<span id="more"></span><!-- more -->

<p>创建一个新目录里面建一个maven pom文件, 添加需要依赖的类库:</p>

<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;com.dep.download&lt;/groupId&gt;
    &lt;artifactId&gt;dep-download&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
 
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.xx.xxx&lt;/groupId&gt;
            &lt;artifactId&gt;yy-yyy&lt;/artifactId&gt;
            &lt;version&gt;x.y.z&lt;/version&gt;
            &lt;scope/&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>

<p>在这个目录下运行命令:<br/><br/>
<code>mvn -f download-dep-pom.xml dependency:copy-dependencies</code></p>

<p>所有跟这个类库相关的直接和间接依赖的jar包都会下载到 ./target/dependency/下</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于serialVersionUID与序列化"]]></title>
    <link href="http://jenwang.me/14853486232320.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486232320.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">java序列化trick and trap</h2>

<p>厂内经常出现序列化对象版本不匹配问题，于是发本文说明一些序列化的注意点</p>

<p><em>调用MQ、memcached、rpc等等涉及到远程通讯的都会经过序列化，虽然客户端透明的封装了细节，但底层是一定会有序列化操作的。因此了解序列化的注意事项是非常有必要的，可以避免误用导致潜在的风险</em></p>

<span id="more"></span><!-- more -->

<ul>
<li><p>通过网络传输的对象，必须实现Serializable接口，或者父类已经实现序列化接口。</p></li>
<li><p>网络传输对象继承层次不宜过深，封装在内部的对象也不宜太复杂。（太复杂很容易出现某个相关的类没实现序列化接口，而导致整个对象无法序列化）</p>

<ul>
<li>一般long/int/String/Map/List/Array等常见类组成的对象就
能解决问题 </li>
<li>最好不要在本应用对外的业务接口中传递或返回“由另一人或系统主导的业务对象&quot;。因为你不能保证别人的对象版本会兼容，从而导致错误扩散</li>
</ul></li>
<li><p>在接口定义上用的是父类，实际远程传输过去的是子类，反序列化不了的。特别是在rpc中客户端容易出现此问题</p></li>
<li><p>远程接口上的参数、返回值类型、会抛出的异常类，都要实现序列化接口。并且server和client都要有对应的类。</p>

<ul>
<li>一个比较容易忽略的例子是:某服务接口可能会抛出某个运行时异常，但没有把这个异常类放入客户端中，一旦抛出此异常，客户端接收到此异常就会无法反序列化</li>
</ul></li>
<li><p>ArrayList.subList()返回的List实现类是内部类型，不能序列化的，通过网络传输会出错。</p></li>
<li><p>ArrayList经过网络传输后，里面的元素顺序可能不一样</p></li>
<li><p>网络传输对象要有无参构造器（如果定义了有参构造器那就要显式定义一个无参构造起），因为机器是不知道传什么内容给有参构造器进行实例化，无参构造器不是public都没关系。没定义无参构造器，有些序列化方式会在底下生成无参构造器的方式才能解决问题。</p></li>
<li><p>网络传输最好不要用enum类型，太强耦合，从网络一端传到另一端，对方可能还是旧版本而识别不了。</p>

<ul>
<li>Enum 常量的序列化不同于普通的 serializable 或 externalizable 对象。enum 常量的序列化形式只包含其名称；常量的字段值不被传送。为了序列化 enum 常量，ObjectOutputStream 需要写入由常量的名称方法返回的字符串。</li>
</ul></li>
<li><p>不需通过网络传输的field用transient定义，但有些json序列化类库是不会区别对待这种field</p></li>
<li><p>有些序列化类库，遇到反序列化不了的类，会反序列化成Map，但会在使用时遇到class cast异常。</p></li>
<li><p>同一应用不要有同package同名的类，可能隐藏在同名/不同名/不同版本的jar中。</p></li>
</ul>

<h2 id="toc_1">serialVersionUID</h2>

<ul>
<li><p><font color="red">用于网络传输的对象，第一次上线使用时，就一定要设定serialVersionUID，不要不顾编译警告</font></p>

<ul>
<li><p>NOTE: 网络对象的匹配，除了靠类名，还靠serialVersionUID，serialVersionUID在《Java语言规范》有固定算法，<u><strong>跟各field的定义相关，如果没有显式赋值，虽然看不见，但会底下会默认算出一个进行网络传输。</strong></u></p></li>
<li><p><font color="red">如果没有显式赋值，在看不见觉察不到的情况下，在你增减了field/修改了定义的情况下，serialVersionUID已被改变，这时网络两端就对接不上而悲剧了。<br/><br/>
没定义serialVersionUID，而又发生了serialVersionUID变化，网络两端只有所有机器都停掉，并且先后起有顺序时，才能不出丝毫差错。</font></p></li>
</ul></li>
<li><p>最好不要用用1L作为serialVersionUID。0L对于java enum的序列化有特殊意义。</p></li>
<li><p>没赋值serialVersionUID 只是警告，不是错误，造成没设定serialVersionUID，网络两端上线运行一段时间也感觉正常。如果再增减修改field，没赋值好serialVersionUID，网络两端就不匹配。 </p>

<ul>
<li>算出旧版本的serialVersionUID（使用serialver或eclipse），设置到新版本的代码中 </li>
</ul></li>
</ul>

<p><em>本文大部分内容取自前同事的分享资料，作了少许修改，<a href="http://lokki.iteye.com/blog/1134482">外网地址</a></em></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一个java内存泄漏的排查案例]]></title>
    <link href="http://jenwang.me/14853486232080.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486232080.html</id>
    <content type="html"><![CDATA[
<p>这是个比较典型的java内存使用问题，定位过程也比较直接，但对新人还是有点参考价值的，所以就纪录了一下。<br/><br/>
下面介绍一下在不了解系统代码的情况下，如何一步步分析和定位到具体代码的排查过程<br/>
<em>（以便新人参考和自己回顾）</em></p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">初步的现象</h2>

<p>业务系统消费MQ中消息速度变慢，积压了200多万条消息，通过jstat观察到业务系统fullgc比较频繁,到最后干脆OOM了：<br/><br/>
<img src="media/14853486232080/14853493912031.jpg" alt=""/></p>

<h2 id="toc_1">进一步分析</h2>

<p><strong>既然知道了内存使用存在问题，那么就要知道是哪些对象占用了大量内存.</strong><br/><br/>
很多人都会想到把堆dump下来再用MAT等工具进行分析，但dump堆要花较长的时间，并且文件巨大，再从服务器上拖回本地导入工具，这个过程太折腾不到万不得已最好别这么干。  </p>

<p>可以用更轻量级的在线分析，用jmap查看存活的对象情况（jmap -histo:live [pid]），可以看出HashTable中的元素有5000多万，占用内存大约1.5G的样子：<br/><br/>
<img src="media/14853486232080/14853494189213.jpg" alt=""/></p>

<h2 id="toc_2">定位到代码</h2>

<p><strong>现在已经知道了是HashTable的问题，那么就要定位出什么代码引起的</strong>    </p>

<p>接下来自然要看看是什么代码往HashTable里疯狂的put数据，于是用神器btrace跟踪Hashtable.put调用的堆栈。<br/><br/>
首先写btrace脚本TracingHashTable.java：</p>

<pre><code>import com.sun.btrace.annotations.*;
import static com.sun.btrace.BTraceUtils.*;

@BTrace
public class TracingHashTable {
        /*指明要查看的方法，类*/
        @OnMethod(
            clazz=&quot;java.util.Hashtable&quot;,
            method=&quot;put&quot;,
            location=@Location(Kind.RETURN))
        public static void traceExecute(@Self java.util.Hashtable object){
                println(&quot;调用堆栈！！&quot;);
                jstack();
        }
}
</code></pre>

<p>然后运行：<br/>
bin/btrace -cp build 4947 TracingHashTable.java<br/><br/>
看到有大量类似下图的调用堆栈<br/><br/>
<img src="media/14853486232080/14853494433131.jpg" alt=""/></p>

<p>可以看出是在接收到消息后查询入库的代码造成的，业务方法调用ibatis再到mysql jdbc驱动执行statement时put了大量的属性到HashTable中。</p>

<p>通过以上排查已基本定位了由那块代码引起的，接下来就是打开代码工程进行白盒化改造了，对相应代码进行优化（不在本文范围内了。几个图中的pid不一致就别纠结了，有些是系统重启过再截图的）.   </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Leiningen的profiles.clj不生效？]]></title>
    <link href="http://jenwang.me/14853486231882.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231882.html</id>
    <content type="html"><![CDATA[
<p>需求:<br/><br/>
比如要自定义本地maven库的路径，又不想在project.clj中定义，因为每个人的本地路径不同，写在工程中不好。那么在profiles.clj中定义比较好：</p>

<pre><code>{:user {:local-repo &quot;D:\\m2\\repository&quot;}}
</code></pre>

<p>当庆幸找到解决方法时，一运行发现根本没生效是件很扫兴的事。<br/>
网上能找到的资料都告诉你profiles.clj这个文件是放在~/.lein/这个目录下的。</p>

<p><strong>实际情况是：</strong> <br/>
<code>如果自定义了LEIN_HOME的路径，那么profiles.clj就应该放在LEIN_HOME目录下，而不是~/.lein/下</code><br/><br/>
否则不会生效，切记。 </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[避免jar依赖冲突的一种办法]]></title>
    <link href="http://jenwang.me/14853486231695.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231695.html</id>
    <content type="html"><![CDATA[
<p>java中的依赖冲突问题一直比较头疼，特别是做公用包给其他系统用的时候，现在都不敢引入太多的依赖，基本上每次都要帮别人解决依赖冲突的问题，非常麻烦。  </p>

<p>特别是碰到一些老系统还不是用maven管理的，人家用你的一个功能还要拷一堆jar包过去，然后排出哪些包在系统中已经有了，版本是否兼容等问题，非常蛋疼。为了方便人家使用就想把所有依赖打成一个jar包提供出去，但这样潜在的依赖冲突问题就会更严重，以后出现冲突时都不知道哪个jar包含了冲突的类。  </p>

<p>更不想引入OSGi这种重量级的东西来隔离依赖。  </p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">一种解决方法</h2>

<p>尝试了多种途径后，发现还是用maven-shade-plugin的relocation方式比较能够满足需要，对于提供基础类库的场景下比较友好。  </p>

<p>原理就是可能把依赖的class重命名包路径，并打包到一个jar中。maven-shade-plugin主要帮我们做了三件事情：  </p>

<ul>
<li>把依赖的class重新放到指定的包下；<br/></li>
<li>改写相关class的字节码，对应于重定义的包路径； </li>
<li><p>把相关依赖的class打进一个jar包；   </p>

<p>这样我们对外提供一个jar包就可以了，显得非常干净，依赖的类被定义到指定的包路径中（比如以当前项目路径为前缀），可以避免跟使用者系统的包冲突。</p>

<p>有时候我们并不希望把所有的依赖都打到一个包中，只想把一部分容易引起冲突的依赖重定义包路径后包含进来，幸运的是maven-shade-plugin很容易做到，并且会把要发布到maven库的pom.xml中的依赖关系都自动改写掉。（通过配置artifactSet中的include和exclude来指定要包含和排除的依赖）</p></li>
</ul>

<h2 id="toc_1">简单例子</h2>

<p>比如我们有这么一个需求：  </p>

<ul>
<li> 假设commons-collections这个包非常容易跟其他系统引起冲突，我们想把它重定义路径后包含到主jar包中； </li>
<li><p>假设我们认为mapdb这个类库一般不会跟别人冲突，不想把它打进主jar包里;  </p>

<p>在pom.xml中定义plugin:  </p>

<pre><code>&lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
        &lt;version&gt;2.1&lt;/version&gt;
        &lt;executions&gt;
            &lt;execution&gt;
                &lt;phase&gt;package&lt;/phase&gt;
                &lt;goals&gt;
                    &lt;goal&gt;shade&lt;/goal&gt;
                &lt;/goals&gt;
                &lt;configuration&gt;
                    &lt;shadedArtifactAttached&gt;false&lt;/shadedArtifactAttached&gt;
                    &lt;!--&lt;shadedClassifierName&gt;standalone&lt;/shadedClassifierName&gt;--&gt;
                    &lt;!--&lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt;--&gt;
                    &lt;!--&lt;shadedArtifactId&gt;jconvert-pinyin-standalone&lt;/shadedArtifactId&gt;--&gt;
                    &lt;!--&lt;shadeSourcesContent&gt;true&lt;/shadeSourcesContent&gt;--&gt;
                    &lt;createSourcesJar&gt;true&lt;/createSourcesJar&gt;
                    &lt;artifactSet&gt;
                        &lt;excludes&gt;
                            &lt;exclude&gt;org.mapdb:*&lt;/exclude&gt;
                        &lt;/excludes&gt;
                    &lt;/artifactSet&gt;
                    &lt;relocations&gt;
                        &lt;relocation&gt;
                            &lt;pattern&gt;org.apache.commons.collections&lt;/pattern&gt;
                            &lt;shadedPattern&gt;com.mycompany.myproject.org.apache.commons.collections&lt;/shadedPattern&gt;
                        &lt;/relocation&gt;
                    &lt;/relocations&gt;
                &lt;/configuration&gt;
            &lt;/execution&gt;
        &lt;/executions&gt;
&lt;/plugin&gt;
</code></pre></li>
</ul>

<p>其中shadedArtifactAttached设为false,表示把shade过的jar作为项目默认的包（发布到maven库时也是shade后的包,发布上去的pom也是改写过的）。如果设为true,则默认的包还是不变,会生成一个独立的shade后的包(这样可以提供2种格式的包,比如让maven工程用户依赖普通的包,非maven用户使用shade过的包)。<br/><br/>
<em>其他详细的参数设置参考 <a href="http://maven.apache.org/plugins/maven-shade-plugin/">maven-shade-plugin官网</a> :</em></p>

<h2 id="toc_2">潜在的问题</h2>

<p>如果第三方包中有反射相关的代码，则shade后可能出现不能正常工作，所以要仔细检查确保不会出现问题</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Java Microbenchmark的一点记录]]></title>
    <link href="http://jenwang.me/14853486231532.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231532.html</id>
    <content type="html"><![CDATA[
<p>大家知道单元测试对代码质量的保障作用已经没什么可说的了。Microbenchmark（微基准测试）也是保证代码质量的重要手段，也是容易忽略的，它用来衡量一些小的代码片段的性能指标，完善的Microbenchmark可以便于定位出一些性能瓶颈,它类似于单元测试,能够进行持续集成,当代码有改动时能够通过持续集成的历史数据 看出对性能的影响点。  </p>

<span id="more"></span><!-- more -->

<p>之前使用Google的Caliper，但目前还在重度开发中，每个版本API变化比较大，还有好些地方不够稳定，所以暂时放弃使用。</p>

<h2 id="toc_0"><a href="http://labs.carrotsearch.com/junit-benchmarks.html">JUnitBenchmark</a></h2>

<p>这里先重点介绍一下JUnitBenchmark的实践，它使用简单，有直观的图表。</p>

<h3 id="toc_1">例子：</h3>

<p>添加依赖：</p>

<pre><code>   &lt;dependency&gt;
        &lt;groupId&gt;com.carrotsearch&lt;/groupId&gt;
        &lt;artifactId&gt;junit-benchmarks&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
        &lt;version&gt;0.7.0&lt;/version&gt;
   &lt;/dependency&gt; 
</code></pre>

<hr/>

<pre><code>@BenchmarkMethodChart(filePrefix = &quot;target/PinyinConvertersBenchmark&quot;)  //指定报表的路径和文件名前缀
@BenchmarkHistoryChart(filePrefix = &quot;target/PinyinConvertersBenchmark-history&quot;, labelWith = LabelType.CUSTOM_KEY, maxRuns = 20)  //设置历史数据报表参数
public class PinyinConvertersBenchmark extends AbstractBenchmark {
    final static Random random = new Random();

    final static HanyuPinyinOutputFormat hanyuPinyinOutputFormat = SimplePinyinConverter.getInstance()
                                                                                    .getDefaultPinyinFormat()
                                                                                    .getPinyin4jOutputFormat();

    @AfterClass
    public static void after() {
        CachedPinyinConverter cachedPinyinConverter = (CachedPinyinConverter) PinyinConverterFactory.CACHED_DEFAULT.get();
        cachedPinyinConverter.dumpCacheInfo(System.out);
        CachedConvertAccess.clear(cachedPinyinConverter);
    }

    //总共运行20w次+5次热身
    @Test
    @BenchmarkOptions(benchmarkRounds = 200000, warmupRounds = 5, clock = Clock.NANO_TIME)
    public void pinyinConverters_ConvertOneStr_CN() throws ConverterException {
        PinyinConverters.toPinyin(&quot;我们对发动过&quot;, &quot;&quot;);
    }

    @Test
    @BenchmarkOptions(benchmarkRounds = 200000, warmupRounds = 5, clock = Clock.NANO_TIME)
    public void pinyin4j_ConvertOneStr_CN() throws BadHanyuPinyinOutputFormatCombination {
        PinyinHelper.toHanyuPinyinString(&quot;我们对发动过&quot;, hanyuPinyinOutputFormat, &quot;&quot;);
    }

    //100个线程运行
    @Test
    @BenchmarkOptions(benchmarkRounds = 200000, warmupRounds = 5, concurrency = 100, clock = Clock.NANO_TIME)
    public void testPutOne_100Thread_CN() {
        testPutOne_OneThread_CN();
    }
}
</code></pre>

<p>然后作为普通单元测试运行就可以了。<br/><br/>
如果需要生产报表,<br/><br/>
1. 要添加jvm参数运行，-Djub.consumers=CONSOLE,H2 -Djub.db.file=./target/.benchmarks<br/><br/>
jub.db.file路径自己定义。<br/><br/>
2. 还需要添加H2的依赖:</p>

<pre><code>    &lt;dependency&gt;
        &lt;groupId&gt;com.h2database&lt;/groupId&gt;
        &lt;artifactId&gt;h2&lt;/artifactId&gt;
        &lt;version&gt;1.3.170&lt;/version&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
</code></pre>

<p>运行后在指定的报表目录下可以找到类似的html报表，对比了总次数、耗时、每个方法的运行时间、gc次数和耗时等数据：  </p>

<p><img src="media/14853486231532/benchmark.jpg" alt="benchmark"/></p>

<h2 id="toc_2">不足之处</h2>

<p>JUnitBenchmark也存在一些不足，报表和功能还不够丰富，只能做一些简单的微基准；使用并发测试时（例如设置concurrency = 100）经常会出现失败,已经反馈了bug,作者表示会尽快修复；<br/><br/>
目前还没有现成的jenkins集成插件。但是JUnitBenchmark还只是alpha阶段，做到这样已经不错了。</p>

<h2 id="toc_3">其他Microbenchmark框架</h2>

<p>以下记录一些Microbenchmark框架，不作详细介绍，有兴趣的慢慢去研究选择适合自己的。  </p>

<h3 id="toc_4"><a href="http://openjdk.java.net/projects/code-tools/jmh/">jmh</a></h3>

<p>ORACLE出品<br/><br/>
<a href="http://assylias.wordpress.com/2013/05/06/java-micro-benchmark-with-jmh-and-netbeans/">http://assylias.wordpress.com/2013/05/06/java-micro-benchmark-with-jmh-and-netbeans/</a><br/><br/>
<a href="https://github.com/nitsanw/jmh-samples">https://github.com/nitsanw/jmh-samples</a></p>

<h3 id="toc_5"><a href="https://japex.java.net/">Japex</a></h3>

<p>需要xml配置，初看配置有点复杂，但图表完善。<br/><br/>
<a href="https://japex.java.net/docs/manual.html">https://japex.java.net/docs/manual.html</a>  </p>

<h3 id="toc_6"><a href="http://www.ellipticgroup.com/misc/projectLibrary.zip">Benchmarking framework</a></h3>

<p><a href="http://www.ellipticgroup.com/misc/projectLibrary.zip">http://www.ellipticgroup.com/misc/projectLibrary.zip</a><br/><br/>
<a href="http://stackoverflow.com/questions/6373550/create-quick-reliable-benchmark-with-java/7120803#7120803">Create quick/reliable benchmark with java</a><br/><br/>
not parameterizable; Java library; JVM micro benchmarking; no plotting; no persistence; no trend analysis; statistics.  </p>

<h3 id="toc_7"><a href="http://commons.apache.org/sandbox/monitoring/">Commons monitoring</a></h3>

<p>not parameterizable!?; Java library; no JVM micro benchmarking!?; plotting; persistence through a servlet; no trend analysis!?; no statistics!?.<br/><br/>
Supports AOP instrumentation.</p>

<h3 id="toc_8"><a href="http://jamonapi.sourceforge.net/">JAMon</a></h3>

<p>not parameterizable; Java library; no JVM micro benchmarking; plotting, persistence and trend analysis with additional tools (Jarep or JMX); statistics.<br/><br/>
Good monitoring, intertwined with log4j, data can also be programmatically accessed or queried and your program can take actions on the results.</p>

<h3 id="toc_9"><a href="http://code.google.com/p/javasimon/">Java Simon</a></h3>

<p>not parameterizable!?; Java library; no JVM micro benchmarking; plotting only with Jarep; persistence only with JMX; no trend analysis; no statistics!?.<br/><br/>
Competitor of Jamon, supports a hierarchy of monitors.</p>

<h3 id="toc_10"><a href="http://jetm.void.fm/index.html">JETM</a></h3>

<p>not parameterizable; Java library; JVM micro benchmarking; plotting; persistence; no trend analysis; no statistics.<br/><br/>
Nice lightweight monitoring tool, no dependencies :) Does not offer sufficient statistics (no standard deviation), and extending the plugIn correspondingly looks quite difficult (Aggregators and Aggregates only have fixed getters for min, max and average). </p>

<h3 id="toc_11"><a href="http://clarkware.com/software/JUnitPerf.html">junitperf</a></h3>

<p>Mainly for doing trend analysis for performance (with the JUnit test decorator TimedTest) and scalability (with the JUnit test decorator LoadTest).<br/><br/>
parameterizable; Java library; no JVM micro benchmarking; no plotting; no persistence; no statistics.</p>

<h3 id="toc_12"><a href="http://perf4j.codehaus.org/">perf4j</a></h3>

<p>not parameterizable; Java library; no JVM micro benchmarking; plotting; persistence via JMX; trend analysis via a log4j appender; statistics.<br/><br/>
Builds upon a logging framework, can use AOP. </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[jenkins集成caliper"]]></title>
    <link href="http://jenwang.me/14853486231362.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231362.html</id>
    <content type="html"><![CDATA[
<p>1.jenkins安装caliper-ci插件(Caliper CI Plugin)</p>

<span id="more"></span><!-- more -->

<p>2.编写microbench<br/><br/>
    最简便的办法就是作为单元测试来跑(这样就不用在jenkins里配置跑microbench的步骤)。<br/>
    编写好microbench后，加一个test方法运行<code>Runner.main(XXXBenchmarksTest.class, new String[] {<br/>
                &quot;--measureMemory&quot;, &quot;--saveResults&quot;, &quot;XXXBenchmarks.caliper.json&quot; });</code>方法,<br/>
    注意指定结果报告的文件位置（这里指定了放在工程的根目录）。</p>

<p>3.在jenkins的job中<code>Add post-build action</code>添加<code>publish caliper microbenchmark results,    JSON result files</code>  这项中填入<code>\*\*/\*.caliper.json</code>，目的就是告诉插件microbenchmark生成的结果文件在哪里，如果不行就到工作区里找一下报告文件生成到哪里了,多试几次看看路径是否设对了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[how-to-octopress"]]></title>
    <link href="http://jenwang.me/14853486231204.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231204.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p>记录一下怎么用octopress的，尼玛一段时间没弄都忘了怎么用这玩意写博客了。</p>

<h2 id="toc_0">windows7</h2>

<ul>
<li><p>安装git</p></li>
<li><p>安装Ruby</p>

<ul>
<li>下载RubyInstaller和DevKit。选rubyinstaller-1.9.2-p290.exe，DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe
<a href="http://rubyforge.org/frs/?group_id=167">http://rubyforge.org/frs/?group_id=167</a>
<a href="https://github.com/oneclick/rubyinstaller/downloads/">https://github.com/oneclick/rubyinstaller/downloads/</a></li>
<li>先安装RubyInstaller，然后解压缩DevKit(路径中不能有中文)。</li>
<li><p>在“Start Command Prompt with Ruby”命令行中进入DevKit解压缩的目录，然后运行以下命令:</p>

<pre><code>ruby dk.rb init  
ruby dk.rb install  
gem install rdiscount --platform=ruby  
cd octopress   
gem install bundler  
bundle install 
</code></pre></li>
<li><p>由于本地原先已经有octopress，执行<code>rake setup_github_pages</code></p></li>
</ul></li>
</ul>

<hr/>

<ul>
<li>写文章</li>
</ul>

<p>rake new_post[&ldquo;title&rdquo;]，会创建一个新的Post，新文件在source/_post下，文件名如下面的格式:2012-07-31-title.markdown。该文件可以直接打开修改。</p>

<ul>
<li>预览效果
在修改设置或者写完文章后，想看看具体效果，可以通过如下命令来完成:</li>
</ul>

<pre><code>set LANG=zh_CN.UTF-8

set LC_ALL=zh_CN.UTF-8

rake generate

rake preview
</code></pre>

<ul>
<li>发布到github</li>
</ul>

<pre><code>rake generate

rake deploy
</code></pre>

<ul>
<li>提交源码</li>
</ul>

<pre><code>git add .

git commit -m &quot;new post&quot;

git push origin source
</code></pre>

<hr/>

<p>windows下可能会在My Octopress Page is coming soon之后出现hellip;不是内部命令之类的错误, 可以不用管, 如果一定不想要出现这个错误可以修改myoctopress目录下的Rakefile, 搜<code>My Octopress Page is coming soon</code>, 在<code>&amp;hellip;</code>前加个<code>^</code>(这个是Windows cmd的转义符), 如下<br/>
<code><br/>
system &quot;echo &#39;My Octopress Page is coming soon ^&amp;hellip;&#39; &gt; index.html&quot;<br/>
</code></p>

<p><code>rake setup_github_pages</code>命令最后出现<code>Now you can deploy to xxxxxxx with rake deploy</code>, 就表示成功.</p>

<p>另外文章的文件格式一定要转化一下（环境变量LANG指定的格式），不然生成会出错</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hbase启动问题记录]]></title>
    <link href="http://jenwang.me/14853486231037.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486231037.html</id>
    <content type="html"><![CDATA[
<p>昨天测试环境的Hbase启动有问题,日志中显示:<br/>
<code>transaction type: 1 error: KeeperErrorCode = NoNode for /hbase</code></p>

<span id="more"></span><!-- more -->

<p>hmaster等其他进程日志中显示连接不上zookeeper，发现zookeeper启动有问题。</p>

<p>于是判断可能是<code>zookeeper</code>中的某些数据丢失了，之前也出现过类似的启动问题，都是清除zookeeper所有数据解决的，这显然不能根本上解决问题。</p>

<p>进一步分析和判断想到hbase的数据目录，由于商测环境是用伪分布式的方式部署的，zookeeper集成在hbase里管理，所以zookeeper的数据也在hbase的临时数据目录下。hbase的临时目录默认是放在/tmp的，而linux的/tmp目录是会被定期清理的(参考linux系统的tmpwatch)。到此问题已基本定位清楚了，修改hbase的临时目录位置，问题解决。</p>

<ul>
<li>hbase.rootdir</li>
</ul>

<p>这个目录是region  server的共享目录，用来持久化Hbase。URL需要是&#39;完全正确&#39;的，还要包含文件系统的scheme。例如，要表示hdfs中的 &lsquo;/hbase&#39;目录，namenode  运行在<code>namenode.example.org</code>的<code>9090</code>端口。则需要设置为<code>hdfs:~/~/namenode.example.org:9000 /hbase</code>。默认情况下Hbase是写到<code>/tmp</code>的。不改这个配置，数据会丢失。     </p>

<p>默认: <code>file:~/~//tmp/hbase-${user.name}/hbase</code></p>

<p>hbase.tmp.dir</p>

<p>本地文件系统的临时文件夹。可以修改到一个更为持久的目录上。(/tmp会清除)     </p>

<p>默认: <code>/tmp/hbase-${user.name}</code></p>

<p><strong>这两点是hadoop/hbase系统部署和运维要重点注意的事项</strong></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[备份新浪微博收藏夹]]></title>
    <link href="http://jenwang.me/14853486230853.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486230853.html</id>
    <content type="html"><![CDATA[
<p>由于要定期对收藏的微博进行整理并删除，又想保留一份原始数据，于是想到了备份一下，在网上找了找没有满意的就自己写了一个，顺便体验一下微博开放的api.</p>

<span id="more"></span><!-- more -->

<p>这个小程序可以备份收藏微博的原始json格式的数据,也可以保存成易读的文本格式，还可以根据自己的需要扩展保存任何想要的格式(比如excel、html等我就不一一实现了)</p>

<p>程序代码放在github上用于学习交流，可以<a href="https://github.com/wq163/weibobak">点击这里查看</a>源代码和文档，或者<a href="/static/weibobak.tar.gz">binary包</a></p>

<p>{% render_partial static/weibobak-README.md %}</p>

<hr/>

<p>下面记录一下使用api几个点，自己的体会，也不一定是最好的方法：<br/><br/>
(以下以我用微博的java sdk写命令行方式的应用来说明)</p>

<p><strong>1. 调用api的准备工作</strong><br/><br/>
首先要在微博开放平台页面上申请并创建一个应用，完成后会分配给应用App Key和App Secret，这两个东西在程序中要用到.就是在Config.properties里 client_ID和client_SERCRET这两个属性</p>

<p><strong>2. 如何在命令行应用里进行oauth2认证</strong><br/><br/>
典型的web应用方式是用户点击后跳转到新浪的账号验证页面，输入账号验证通过后回调到应用的页面并在url中带上code值，然后我们用这个code获取AccessToken，这个AccessToken就是授权我们访问数据的凭证。</p>

<p>按照SDK中提供的api是在浏览器中进行交互的，而我只想写个简单的java命令行应用，不想弄web应用。命令行中调用浏览器进行认证后，我的程序无法获得返回的code，也就没法获取到AccessToken(我可不想人工介入,我只想输入自己的微博账号就搞定)。于是想到程序中模拟浏览器请求（也就是页面中输入账号后提交的那一步），通过抓包获知提交请求所需的参数主要有这么几个:  </p>

<pre><code class="language-java">PostParameter[] params =
     new PostParameter[] { new PostParameter(&quot;withOfficalFlag&quot;, 0),
                          new PostParameter(&quot;response_type&quot;, &quot;code&quot;),
                          new PostParameter(&quot;redirect_uri&quot;, Config.getValue(&quot;redirect_URI&quot;).trim()),
                          new PostParameter(&quot;client_id&quot;, Config.getValue(&quot;client_ID&quot;).trim()),
                          new PostParameter(&quot;action&quot;, &quot;submit&quot;),
                          new PostParameter(&quot;userId&quot;, Config.getValue(&quot;userId&quot;).trim()),
                          new PostParameter(&quot;passwd&quot;, Config.getValue(&quot;passwd&quot;).trim()),
                          new PostParameter(&quot;isLoginSina&quot;, &quot;&quot;), new PostParameter(&quot;regCallback&quot;, &quot;&quot;),
                          new PostParameter(&quot;state&quot;, &quot;&quot;), new PostParameter(&quot;from&quot;, &quot;&quot;) };
</code></pre>

<p>并且要增加http header：</p>

<pre><code class="language-java">postMethod.addRequestHeader(&quot;Referer&quot;,
        &quot;https://api.weibo.com/oauth2/authorize?client_id=2671507095&amp;redirect_uri=http://jenwang.org&amp;response_type=code&quot;);
postMethod.addRequestHeader(&quot;User-Agent&quot;,
        &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.151 Safari/535.19&quot;);
                
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一次使用octopress,中文问题的解决办法"]]></title>
    <link href="http://jenwang.me/14853486230436.html"/>
    <updated>2017-01-25T20:50:23+08:00</updated>
    <id>http://jenwang.me/14853486230436.html</id>
    <content type="html"><![CDATA[
<p>文章内容和分类中有中文比较麻烦，网上找了很多方法都不管用,我在windows7下cywin的解决办法是： </p>

<ol>
<li>把文章的makedown文件保存成为无BOM的utf-8格式。</li>
<li>控制台或脚本中在rake generate命令后加上export LC_ALL=zh_CN.UTF-8和export LANG=zh_CN.UTF-8</li>
</ol>

<p>两步骤缺一不可</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[title: "淘宝消息中间件Metamorphosis开源"]]></title>
    <link href="http://jenwang.me/14853499458621.html"/>
    <updated>2017-01-25T21:12:25+08:00</updated>
    <id>http://jenwang.me/14853499458621.html</id>
    <content type="html"><![CDATA[
<p><img src="media/14853499458621/meta.jpg" alt="meta"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[title: "MappedByteBuffer引起的jvm crash问题“]]></title>
    <link href="http://jenwang.me/14853499458835.html"/>
    <updated>2017-01-25T21:12:25+08:00</updated>
    <id>http://jenwang.me/14853499458835.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="media/14853499458835/mmap-crash.jpg" alt="mmap-crash"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[title: "关于BeanUtils拷贝null属性的问题"]]></title>
    <link href="http://jenwang.me/14853499456673.html"/>
    <updated>2017-01-25T21:12:25+08:00</updated>
    <id>http://jenwang.me/14853499456673.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="media/14853499456673/beanutils-null.jpg" alt="beanutils-nul"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[title: "hadoop单元测试方法--使用和增强]]></title>
    <link href="http://jenwang.me/14853499459066.html"/>
    <updated>2017-01-25T21:12:25+08:00</updated>
    <id>http://jenwang.me/14853499459066.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="media/14853499459066/mrunit1.jpg" alt="mrunit1"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[title: "JUC代码浅析[6]——基于AQS的CyclicBarrier"]]></title>
    <link href="http://jenwang.me/14853499457810.html"/>
    <updated>2017-01-25T21:12:25+08:00</updated>
    <id>http://jenwang.me/14853499457810.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="media/14853499457810/juc-CyclicBarrier.jpg" alt="juc-CyclicBarrie"/></p>

]]></content>
  </entry>
  
</feed>
